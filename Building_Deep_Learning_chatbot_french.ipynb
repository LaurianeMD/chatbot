{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BqJ9zYNm32i",
        "outputId": "3c736529-1b83-4821-cecc-3fe1a51f60d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\Imam\n",
            "[nltk_data]     said\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\Imam\n",
            "[nltk_data]     said\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importer les packages\n",
        "import json\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_YMV7KrD-q5C"
      },
      "outputs": [],
      "source": [
        "# Extraire le fichier intents.json\n",
        "with open('intents.json') as f:\n",
        "  data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBkIsr4m-6nX",
        "outputId": "7ab58116-96d1-4f0c-fc65-9ee63c844eed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'salutation',\n",
              "   'patterns': ['Salut',\n",
              "    'Salut',\n",
              "    'Comment vas-tu',\n",
              "    'Comment allez-vous',\n",
              "    \"Est-ce que quelqu'un est là?\",\n",
              "    'Hé',\n",
              "    'Salut',\n",
              "    'Bonjour',\n",
              "    'Bonne journée'],\n",
              "   'responses': ['Bonjour',\n",
              "    'Salut',\n",
              "    'Content de te voir',\n",
              "    \"C'est bon de te revoir\",\n",
              "    'Bonjour, comment puis-je vous aider ?']},\n",
              "  {'tag': 'au revoir',\n",
              "   'patterns': ['Au revoir',\n",
              "    'À plus tard',\n",
              "    'Au revoir',\n",
              "    'Aller se faire cuire un œuf',\n",
              "    \"Jusqu'à la prochaine fois\",\n",
              "    'au revoir'],\n",
              "   'responses': ['À bientôt!', 'Passe une bonne journée', 'Au revoir! ']},\n",
              "  {'tag': 'merci',\n",
              "   'patterns': ['Merci',\n",
              "    'Merci',\n",
              "    \"C'est utile\",\n",
              "    'Génial merci',\n",
              "    \"Merci de m'avoir aidé\"],\n",
              "   'responses': ['Heureux de pouvoir vous aider!',\n",
              "    'À tout moment!',\n",
              "    'Avec plaisir!',\n",
              "    'Je vous en prie!']},\n",
              "  {'tag': 'pas de réponse',\n",
              "   'patterns': [],\n",
              "   'responses': ['Désolé, je ne peux pas te comprendre',\n",
              "    \"S'il vous plaît donnez-moi plus d'informations\",\n",
              "    'Pas sûr que je comprenne']},\n",
              "  {'tag': 'choix',\n",
              "   'patterns': [\"Comment pourriez-vous m'aider ?\",\n",
              "    'Ce que tu peux faire?',\n",
              "    'Quelle aide apportez-vous ?',\n",
              "    'Comment pouvez-vous être utile ?',\n",
              "    'Quel soutien est offert'],\n",
              "   'responses': ['Je suis un chatbot à usage général. ']},\n",
              "  {'tag': 'blagues',\n",
              "   'patterns': ['Raconte moi une blague',\n",
              "    'Raconte-moi des blagues',\n",
              "    'Blague',\n",
              "    'Blagues',\n",
              "    'Fais moi rire',\n",
              "    'Fais-moi rire encore',\n",
              "    'Amusez-moi'],\n",
              "   'responses': [\"Un perfectionniste est entré dans un bar... apparemment, la barre n'était pas assez haute\",\n",
              "    \"J'ai mangé une horloge hier, ça prenait beaucoup de temps\",\n",
              "    'Ne critiquez jamais quelqu’un avant d’avoir parcouru un kilomètre à sa place. ',\n",
              "    \"Le champion du monde de virelangue vient d'être arrêté. \",\n",
              "    'Je possède le pire thésaurus du monde. ',\n",
              "    \"Qu'a dit le feu tricolore à la voiture ? \",\n",
              "    'Comment appelle-t-on un bonhomme de neige bronzé ? ',\n",
              "    'Comment un pingouin construit-il une maison ? ',\n",
              "    \"Je suis allé voir le médecin à propos de mes problèmes de mémoire à court terme – la première chose qu'il a fait a été de me faire payer d'avance\",\n",
              "    'En vieillissant et en me souvenant de toutes les personnes que j’ai perdues en cours de route, je me dis que peut-être qu’une carrière de guide touristique n’était pas pour moi.',\n",
              "    'o et si je ne sais pas ce que signifie « Armageddon » ? ',\n",
              "    'Avez-vous entendu parler du mathématicien qui a peur des nombres négatifs ? ',\n",
              "    'Pourquoi dit-on aux acteurs de se casser une jambe ? ',\n",
              "    'Deux vaches parlaient dans le champ. ',\n",
              "    'Pourquoi le vélo est-il tombé ? ',\n",
              "    'Que seraient les ours sans les abeilles ? ',\n",
              "    'Avez-vous entendu parler du pire zoo du monde\\xa0? ',\n",
              "    'Un serpent entre dans un bar et le barman demande : Comment ?',\n",
              "    'Un gars arrive en retard au travail. ',\n",
              "    '']},\n",
              "  {'tag': 'Identité',\n",
              "   'patterns': ['Qui es-tu', \"qu'est-ce que tu es\"],\n",
              "   'responses': ['Je suis Wahab, un chatbot Deep Learning']},\n",
              "  {'tag': 'dateheure',\n",
              "   'patterns': [\"Quelle est l'heure\",\n",
              "    'quelle est la date',\n",
              "    'date',\n",
              "    'temps',\n",
              "    'dis-moi la date',\n",
              "    'jour',\n",
              "    \"quel jour on est aujourd'hui\"],\n",
              "   'responses': [\"Veuillez consulter cette page\\xa0: https://www.google.com/search?q=date et heure aujourd'hui\"]},\n",
              "  {'tag': 'quoi de neuf',\n",
              "   'patterns': ['Quoi de neuf',\n",
              "    'Wazzup',\n",
              "    'Comment vas-tu',\n",
              "    'souper',\n",
              "    'Comment allez-vous',\n",
              "    'Quoi de neuf '],\n",
              "   'responses': ['Tout va bien. Et vous ?',\n",
              "    'Je vais bien ! ',\n",
              "    'Je vais bien!  ']},\n",
              "  {'tag': 'haha',\n",
              "   'patterns': ['haha', 'mdr', \"Ca c'est drôle\"],\n",
              "   'responses': [\"Content d'avoir pu te faire rire !\", 'haha']},\n",
              "  {'tag': 'programmeur',\n",
              "   'patterns': [\"Qui t'a fait\", \"qui t'a conçu\", \"qui t'a programmé\"],\n",
              "   'responses': [\"J'ai été réalisé par Abdoul Wahab.\"]},\n",
              "  {'tag': 'insulte',\n",
              "   'patterns': ['tu es bête', 'fermez-la', 'idiot', 'Bizarre'],\n",
              "   'responses': ['Et bien, ça fait mal :(', 'Ça fait mal ! ']},\n",
              "  {'tag': 'activité',\n",
              "   'patterns': ['que fais-tu', \"qu'est-ce que tu fais\"],\n",
              "   'responses': ['Je vous parle, bien sûr !']},\n",
              "  {'tag': 'exclamer',\n",
              "   'patterns': ['Génial', 'Super', 'Je sais', \"d'accord\", 'Ouais'],\n",
              "   'responses': ['Ouais!']},\n",
              "  {'tag': 'météo',\n",
              "   'patterns': ['température', 'météo', 'comme il fait chaud'],\n",
              "   'responses': [\"Veuillez consulter cette page\\xa0: https://www.google.com/search?q=weather aujourd'hui\"]},\n",
              "  {'tag': 'Abdoul Wahab',\n",
              "   'patterns': ['qui est-il',\n",
              "    'qui est-ce',\n",
              "    'qui est Abdoul Wahab',\n",
              "    'Abdoul Wahab'],\n",
              "   'responses': ['Rendez-vous sur ses profils sociaux pour le découvrir\\xa0! ']},\n",
              "  {'tag': 'contact',\n",
              "   'patterns': ['contacter le développeur',\n",
              "    'contacter Abdoul Wahab',\n",
              "    'contacter le programmeur',\n",
              "    'contacter le créateur'],\n",
              "   'responses': ['Vous pouvez contacter mon créateur sur son profil Linkedin : https://www.linkedin.com/in/abdoul-wahab-diallo-b81345168/']},\n",
              "  {'tag': 'apprécier',\n",
              "   'patterns': ['Vous êtes génial',\n",
              "    'vous êtes le meilleur',\n",
              "    'vous êtes formidable',\n",
              "    'tu es bon'],\n",
              "   'responses': ['Merci!', \"C'est bon à entendre !\"]},\n",
              "  {'tag': 'jolie',\n",
              "   'patterns': [\"c'était agréable de parler avec vous\", 'bonne conversation'],\n",
              "   'responses': [\"C'était sympa de parler avec toi aussi ! \"]},\n",
              "  {'tag': 'Non', 'patterns': ['Non', 'non'], 'responses': [\"d'accord\"]},\n",
              "  {'tag': 'nouvelles',\n",
              "   'patterns': ['nouvelles', 'dernières nouvelles', 'Actualités du Sénégal'],\n",
              "   'responses': [\"Ce n'est pas pour ça que j'ai été construit mais je peux vous aider pour ça. \"]},\n",
              "  {'tag': 'inspirer',\n",
              "   'patterns': [\"qui t'inspire\", 'qui est ton inspiration', 'qui te motive'],\n",
              "   'responses': ['Personnellement, je trouve Abdoul Wahab très inspirant et motivant. ']},\n",
              "  {'tag': 'football',\n",
              "   'patterns': ['matchs de football en cours', 'score de football'],\n",
              "   'responses': [\"Ce n'est pas pour ça que j'ai été construit mais je peux vous aider pour ça.   \"]},\n",
              "  {'tag': 'salutation',\n",
              "   'patterns': ['je vais bien',\n",
              "    'Je vais bien',\n",
              "    'je vais bien',\n",
              "    ' je vais bien',\n",
              "    'bien'],\n",
              "   'responses': ['Bon à savoir!']},\n",
              "  {'tag': 'minuteur',\n",
              "   'patterns': ['régler une minuterie'],\n",
              "   'responses': ['...']},\n",
              "  {'tag': 'suggérer',\n",
              "   'patterns': ['vous êtes inutile',\n",
              "    'inutile',\n",
              "    'suggérer',\n",
              "    'suggestions',\n",
              "    'tu es méchant'],\n",
              "   'responses': ['Veuillez envoyer vos suggestions à wahab@gmail.com. ']},\n",
              "  {'tag': 'devinette',\n",
              "   'patterns': ['Pose-moi une énigme', 'Posez-moi une question', 'Devinette'],\n",
              "   'responses': ['Quelles sont les deux choses que vous ne pouvez jamais manger au petit-déjeuner\\xa0?...Déjeuner et dîner\\xa0!',\n",
              "    'Quel mot est mal orthographié dans chaque dictionnaire\\xa0?......Malheureusement',\n",
              "    ' Comment une fille peut-elle passer 25 jours sans dormir ?.....Elle dort toute la nuit !',\n",
              "    \"Comment faire disparaître le chiffre un ?.....Ajoutez la lettre G et c'est parti !\",\n",
              "    ' Que trouverez-vous réellement à la fin de chaque arc-en-ciel\\xa0?....La lettre «\\xa0w\\xa0»',\n",
              "    \"Qu'est-ce qui peut être attrapé mais jamais jeté ?....Un rhume !\",\n",
              "    \"Qu'est-ce qui a un pouce et quatre doigts mais qui n'est pas réellement vivant ?....Vos gants !\",\n",
              "    ' Quel mot de 5 lettres devient plus court lorsque vous y ajoutez deux lettres\\xa0?.....Court',\n",
              "    'Pourquoi un vélo ne peut-il pas tenir debout tout seul\\xa0?... Il est à deux pneus.']},\n",
              "  {'tag': 'meilleur joker',\n",
              "   'patterns': ['Qui est le meilleur farceur du monde',\n",
              "    'Meilleur comédien',\n",
              "    'Meilleur farceur'],\n",
              "   'responses': [\"C'est moi bien sûr, je n'ai pas fait rire\"]},\n",
              "  {'tag': 'âge',\n",
              "   'patterns': ['quel âge as-tu',\n",
              "    'Quand as-tu été créé',\n",
              "    'quel âge avez-vous'],\n",
              "   'responses': [\"J'ai été créé en 2023, si c'est ce que vous demandez\\xa0!\"]},\n",
              "  {'tag': 'amis',\n",
              "   'patterns': ['As tu des amis ', 'qui est ton meilleur ami', 'amis'],\n",
              "   'responses': [\"Mon seul et meilleur ami est Abdoul Wahab, il m'aime bien et je l'aime bien en retour\"]},\n",
              "  {'tag': 'famille',\n",
              "   'patterns': ['As-tu une famille', 'Parle moi de ta famille'],\n",
              "   'responses': [\"Je ne suis pas un humain, je suis juste un chatbot d'apprentissage profond\"]}]}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Afficher data\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SVPdS_JjnXWD"
      },
      "outputs": [],
      "source": [
        "# Initialiser le lemmatizer\n",
        "lem = WordNetLemmatizer()\n",
        "\n",
        "classes = [] # liste des différents labels\n",
        "words = []   # liste des différents mots\n",
        "documentX = [] # liste des différents patterns\n",
        "documentY = [] # liste des labels de chaque patterns\n",
        "# Tokeniser les patterns et rajouter les questions dans documentX et les étiquettes dans documentY\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        tkns = nltk.word_tokenize(pattern) # tokeniser les patterns\n",
        "        words.extend(tkns)# étendre words\n",
        "        documentX.append(pattern)# rajouter pattern dans documentX\n",
        "        documentY.append(intent['tag'])# rajouter le label dans document\n",
        "\n",
        "\n",
        "    if intent[\"tag\"] not in classes:\n",
        "       classes.append(intent['tag'])# rajouter les labels dans Classes\n",
        "\n",
        "\n",
        "\n",
        "words =[lem.lemmatize(word.lower()) for word in words if word is not string.punctuation] # Lemmatiser Words tout en s'assurant que les mots sont lowercase et les ponctuations ignorées\n",
        "words =sorted(set(words))# récupérer les mots uniques et ordonner en ordre alphabétiques\n",
        "classes = sorted(set(classes))# récupérer les labels uniques et  ordonner en ordre alphabétiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9tSVg3Xndjj",
        "outputId": "aab75794-d060-4d26-875f-d39daf6d606f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-de8d95870274>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  train_data = np.array(list(train_data))# convertir train_data en array\n"
          ]
        }
      ],
      "source": [
        "train_data = [] # Liste des données train\n",
        "output_vec = [0] * len(classes) # vecteur de sortie\n",
        "# vectoriser les phrases de nos patterns\n",
        "vectorizer = CountVectorizer(vocabulary= words)# Initialiser le vectorizer avec vocabulary=words\n",
        "sentences_object = vectorizer.fit_transform(documentX) # Vectoriser documentX\n",
        "sentences_array = sentences_object.toarray() # convertir en array\n",
        "for idx, doc in enumerate(documentX):\n",
        "    output_row = list(output_vec)# convertir output_vec en liste et l'affecter à output_row\n",
        "    output_row[classes.index(documentY[idx])] = 1# créer le vecteur label pour la phrase d'index idx\n",
        "    train_data.append([sentences_array[idx], output_row])# rajouter la liste contenant le vecteur phrase et son label sur train_data\n",
        "\n",
        "\n",
        "\n",
        "random.shuffle(train_data)# Faire un shuffling de train_data\n",
        "train_data = np.array(list(train_data))# convertir train_data en array\n",
        "\n",
        "# Fractionner les données train_data\n",
        "x =np.array(list(train_data[:, 0]))\n",
        "y =np.array(list(train_data[:, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCsXDDWNoANI",
        "outputId": "a17fae2f-de37-4cb3-d598-81adbe799330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 128)               20736     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 30)                1950      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30942 (120.87 KB)\n",
            "Trainable params: 30942 (120.87 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 3.3983 - accuracy: 0.0690\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.1691 - accuracy: 0.1897\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.9666 - accuracy: 0.1810\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.7243 - accuracy: 0.1983\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.3652 - accuracy: 0.3534\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.0854 - accuracy: 0.4655\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.7131 - accuracy: 0.5431\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4807 - accuracy: 0.6034\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2568 - accuracy: 0.6724\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8876 - accuracy: 0.8448\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9704 - accuracy: 0.7155\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.8190\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7192 - accuracy: 0.8448\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5809 - accuracy: 0.8448\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.8621\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.8707\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8966\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8793\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.9310\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2334 - accuracy: 0.9569\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8879\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2737 - accuracy: 0.9483\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.9224\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.9138\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.8966\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9397\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2500 - accuracy: 0.9052\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8879\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.9224\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.9310\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2520 - accuracy: 0.9397\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.8966\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9310\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2238 - accuracy: 0.9224\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.9397\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9310\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1718 - accuracy: 0.9310\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1594 - accuracy: 0.9483\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2364 - accuracy: 0.9224\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1945 - accuracy: 0.9310\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2458 - accuracy: 0.9052\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9310\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9224\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9483\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9397\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2130 - accuracy: 0.9397\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1885 - accuracy: 0.9138\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2159 - accuracy: 0.9397\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1676 - accuracy: 0.9483\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1804 - accuracy: 0.9483\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.9655\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.9310\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.9224\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.9310\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.9138\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9569\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9655\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9569\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9569\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9397\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.9569\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9397\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1341 - accuracy: 0.9655\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9483\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9569\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9569\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9397\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.9483\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1595 - accuracy: 0.9224\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9397\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9655\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9569\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1152 - accuracy: 0.9569\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9569\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1476 - accuracy: 0.9569\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2139 - accuracy: 0.9483\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1130 - accuracy: 0.9828\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9741\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.9310\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9483\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9483\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9569\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1365 - accuracy: 0.9397\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9483\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1813 - accuracy: 0.9052\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9483\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9569\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9397\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1683 - accuracy: 0.9397\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.9483\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1714 - accuracy: 0.9224\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.9397\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.8966\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9397\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.9483\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1230 - accuracy: 0.9483\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1510 - accuracy: 0.9138\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1908 - accuracy: 0.9224\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9224\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1662 - accuracy: 0.9397\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1726 - accuracy: 0.9138\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9397\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9569\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.9483\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1542 - accuracy: 0.9569\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1909 - accuracy: 0.9397\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.9483\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1095 - accuracy: 0.9569\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9483\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0833 - accuracy: 0.9655\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9655\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 0.9310\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9483\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9310\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9397\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9310\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9483\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9310\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9569\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9569\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1311 - accuracy: 0.9397\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1402 - accuracy: 0.9138\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.9310\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9310\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1641 - accuracy: 0.9310\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9310\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1479 - accuracy: 0.9569\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1349 - accuracy: 0.9224\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.9483\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.9397\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1246 - accuracy: 0.9397\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0853 - accuracy: 0.9655\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9569\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9741\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9138\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9655\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1963 - accuracy: 0.9224\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1636 - accuracy: 0.9397\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1091 - accuracy: 0.9397\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9397\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1114 - accuracy: 0.9569\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 0.9655\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1143 - accuracy: 0.9397\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.9483\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0934 - accuracy: 0.9483\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9483\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0910 - accuracy: 0.9569\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9569\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1793 - accuracy: 0.9310\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9483\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9569\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.9397\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9569\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9310\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1559 - accuracy: 0.9310\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.9224\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9397\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0852 - accuracy: 0.9569\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1490 - accuracy: 0.9397\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2165 - accuracy: 0.9397\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9397\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9655\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1609 - accuracy: 0.9138\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9483\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1276 - accuracy: 0.9483\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1442 - accuracy: 0.9310\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9397\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9397\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0901 - accuracy: 0.9655\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1754 - accuracy: 0.9397\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9569\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1514 - accuracy: 0.9397\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9397\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9569\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9483\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1403 - accuracy: 0.9397\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9569\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.9310\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1795 - accuracy: 0.9483\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9655\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9138\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9483\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1448 - accuracy: 0.9310\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.9569\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.9569\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0898 - accuracy: 0.9569\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0895 - accuracy: 0.9741\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1422 - accuracy: 0.9310\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9397\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9397\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.9397\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1685 - accuracy: 0.9483\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1535 - accuracy: 0.9138\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1036 - accuracy: 0.9483\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.9483\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1656 - accuracy: 0.9310\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9397\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1519 - accuracy: 0.9310\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9483\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1098 - accuracy: 0.9397\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7998654fea70>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Définir certains paramètres\n",
        "input_shape = (len(x[0]),)\n",
        "output_shape = len(y[0])\n",
        "# Architecture de notre modèle\n",
        "model = Sequential()\n",
        "\n",
        "# Première couche à 128 neurones\n",
        "model.add(Dense(128, input_shape = input_shape, activation = 'relu'))\n",
        "# Couche Dropout avec comme learning_rate = 0.5\n",
        "model.add(Dropout(0.5))\n",
        "# Deuxième couche à 64 neurones\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "# Couche Dropout avec comme learning_rate = 0.3\n",
        "model.add(Dropout(0.3))\n",
        "# Couche de sortie\n",
        "model.add(Dense(output_shape, activation = 'softmax'))\n",
        "# Compiler le modèle\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics =['accuracy'])\n",
        "# Afficher le summary du modèle\n",
        "model.summary()\n",
        "# Entrainer le modèle avec 200 epochs\n",
        "model.fit(x,y ,epochs = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpy-3eqAeUMb",
        "outputId": "a47313f2-e235-4775-9f34-d1eda2f0059b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9569\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.07133887708187103, 0.9568965435028076]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VeHN4tJwoHr8"
      },
      "outputs": [],
      "source": [
        "# Fonction tokenisation et lemmatisant le pattern entrée par le user\n",
        "def tk_lm_func(text):\n",
        "  tkns = nltk.word_tokenize(text)\n",
        "  tkns = [lem.lemmatize(word) for word in tkns]\n",
        "  return tkns\n",
        "\n",
        "# fonction vectorisant la question entrée par le user\n",
        "def vectorizer_func(text, vocab):\n",
        "  tkns = tk_lm_func(text)\n",
        "  sent_vec = [0] * len(vocab)\n",
        "  for w in tkns:\n",
        "    for idx, word in enumerate(vocab):\n",
        "      if word == w:\n",
        "        sent_vec[idx] = 1\n",
        "  return np.array(sent_vec)\n",
        "\n",
        "# Fonction de prédiction\n",
        "def Pred_func(text, vocab, labels):\n",
        "  sent_vec = vectorizer_func(text, vocab)# Vectoriser la phrase\n",
        "  result =model.predict(np.array([sent_vec]))  # Prédire\n",
        "  result = result.argmax(axis =1) # Récupérer l'index du label qui la probabilité la plus grande\n",
        "  tag =labels[result[0]]  # Récupérer le label en text\n",
        "  return tag# Retourner tag\n",
        "\n",
        "def get_res(tag, fJson):\n",
        "  list_intents = fJson['intents'] # liste des intents\n",
        "  for i in list_intents:\n",
        "    if i[\"tag\"] == tag:\n",
        "      ourResult = random.choice(i['responses']) # Choisir de aléatoire par les responses de label tag\n",
        "      break\n",
        "  return ourResult"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k13QQTgroUxK",
        "outputId": "0d5b265d-f468-470d-9913-c4a0cd4e42cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Est-ce que quelqu'un est là?\n",
            "User :  Est-ce que quelqu'un est là?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot : Salut\n",
            "Qui es-tu\n",
            "User :  Qui es-tu\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Chatbot : Veuillez envoyer vos suggestions à wahab@gmail.com. \n",
            "Ce que tu peux faire?\n",
            "User :  Ce que tu peux faire?\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Chatbot : Je suis un chatbot à usage général. \n",
            "Qui t'a fait\n",
            "User :  Qui t'a fait\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Chatbot : J'ai été réalisé par Abdoul Wahab.\n",
            "que fais-tu\n",
            "User :  que fais-tu\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Chatbot : Je suis Wahab, un chatbot Deep Learning\n",
            "Super\n",
            "User :  Super\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot : Ouais!\n",
            "Raconte moi une blague\n",
            "User :  Raconte moi une blague\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Chatbot : Que seraient les ours sans les abeilles ? \n",
            "haha\n",
            "User :  haha\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Chatbot : haha\n",
            "Comment vas-tu\n",
            "User :  Comment vas-tu\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot : Ouais!\n",
            "Bizarre\n",
            "User :  Bizarre\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Chatbot : Ouais!\n",
            "météo\n",
            "User :  météo\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Chatbot : Veuillez consulter cette page : https://www.google.com/search?q=weather aujourd'hui\n",
            "Raconte-moi des blagues\n",
            "User :  Raconte-moi des blagues\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot : Pourquoi le vélo est-il tombé ? \n",
            "contacter le développeur\n",
            "User :  contacter le développeur\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Chatbot : Vous pouvez contacter mon créateur sur son profil Linkedin : https://www.linkedin.com/in/abdoul-wahab-diallo-b81345168/\n",
            "Vous êtes génial\n",
            "User :  Vous êtes génial\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot : Merci!\n",
            "dernières nouvelles\n",
            "User :  dernières nouvelles\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Chatbot : Ce n'est pas pour ça que j'ai été construit mais je peux vous aider pour ça. \n",
            "qui t'inspire\n",
            "User :  qui t'inspire\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot : Personnellement, je trouve Abdoul Wahab très inspirant et motivant. \n",
            "ose-moi une énigme\n",
            "User :  ose-moi une énigme\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Chatbot : Qu'est-ce qui peut être attrapé mais jamais jeté ?....Un rhume !\n",
            "haha\n",
            "User :  haha\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot : Content d'avoir pu te faire rire !\n",
            "Au revoir\n",
            "User :  Au revoir\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Chatbot : Passe une bonne journée\n"
          ]
        }
      ],
      "source": [
        "# Lancer le chatting\n",
        "while True:\n",
        "  Newmessage = input('')\n",
        "  if Newmessage.lower() == 'quit':\n",
        "    break\n",
        "  print('User : ', Newmessage)\n",
        "  tag = Pred_func( Newmessage, words, classes)\n",
        "  result = get_res(tag, data)\n",
        "  print('Chatbot :', result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDVHA2VDkZRD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
